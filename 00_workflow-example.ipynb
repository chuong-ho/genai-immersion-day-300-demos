{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad94911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.environ.get('openai_api_key')\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"‚ö†Ô∏è  openai_api_key not found in .env file\")\n",
    "else:\n",
    "    print(\"‚úì OpenAI API key loaded from .env file\")\n",
    "    \n",
    "# Get Gemini API key\n",
    "gemini_api_key = os.environ.get('gemini_api_key')\n",
    "\n",
    "if not gemini_api_key:\n",
    "    print(\"‚ö†Ô∏è  gemini_api_key not found in .env file\")\n",
    "    print(\"Please add: gemini_api_key=your-api-key to .env file\")\n",
    "else:\n",
    "    print(\"‚úì Gemini API key loaded from .env file\")\n",
    "    \n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e371ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a test to make sure it is working\n",
    "user_prompt = \"Who am I talking to?\"\n",
    "\n",
    "print(f\"\\nüì§ Sending to openai: {user_prompt}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Send to openai\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # or \"gpt-3.5-turbo\" for faster/cheaper responses\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get the response\n",
    "ai_response = response.choices[0].message.content\n",
    "\n",
    "print(\"\\nüì• openai Response:\")\n",
    "print(ai_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b8683",
   "metadata": {},
   "source": [
    "## Advanced: Gradio Chatbot with Conversation History\n",
    "\n",
    "This creates a chatbot interface that remembers your conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce61d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def dual_ai_response(message):\n",
    "    \"\"\"\n",
    "    Get OpenAI response and Gemini evaluation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get OpenAI response\n",
    "        openai_response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": message}]\n",
    "        )\n",
    "        openai_answer = openai_response.choices[0].message.content\n",
    "        \n",
    "        # Get Gemini evaluation\n",
    "        gemini_prompt = f\"\"\"Evaluate this AI response:\n",
    "\n",
    "Question: {message}\n",
    "Response: {openai_answer}\n",
    "\n",
    "Rate it (1-10) and explain why. Is it accurate and helpful?\"\"\"\n",
    "        \n",
    "        gemini_response = gemini_model.generate_content(gemini_prompt)\n",
    "        gemini_evaluation = gemini_response.text\n",
    "        \n",
    "        return openai_answer, gemini_evaluation\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"Unable to evaluate\"\n",
    "\n",
    "# Create custom interface with two output boxes\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# AI Response with Gemini Quality Check\")\n",
    "    gr.Markdown(\"Ask a question to OpenAI GPT-4, and Gemini will evaluate the response quality!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            user_input = gr.Textbox(\n",
    "                label=\"Your Question\", \n",
    "                lines=3,\n",
    "                placeholder=\"Ask anything...\"\n",
    "            )\n",
    "            submit_btn = gr.Button(\"üöÄ Ask & Evaluate\", variant=\"primary\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            openai_output = gr.Textbox(\n",
    "                label=\"ü§ñ OpenAI GPT-4 Response\", \n",
    "                lines=15,\n",
    "                show_copy_button=True\n",
    "            )\n",
    "        with gr.Column():\n",
    "            gemini_output = gr.Textbox(\n",
    "                label=\"‚ú® Gemini Quality Evaluation\", \n",
    "                lines=15,\n",
    "                show_copy_button=True\n",
    "            )\n",
    "    \n",
    "    # Example questions\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            \"Explain quantum computing in simple terms\",\n",
    "            \"Write a haiku about artificial intelligence\",\n",
    "            \"What is the difference between machine learning and deep learning?\",\n",
    "            \"How does photosynthesis work?\"\n",
    "        ],\n",
    "        inputs=user_input\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=dual_ai_response,\n",
    "        inputs=user_input,\n",
    "        outputs=[openai_output, gemini_output]\n",
    "    )\n",
    "\n",
    "# Launch with public sharing enabled\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Gradio interface\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
